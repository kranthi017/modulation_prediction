{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "(30000, 1024, 2)\n",
      "0.81229824\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File('data.hdf5', 'r')\n",
    "\n",
    "import numpy as np\n",
    "print(list(f.keys()))\n",
    "test = f['test']\n",
    "test_data=np.array(test)\n",
    "train = f['train']\n",
    "train_data=np.array(train)\n",
    "print(type(train))\n",
    "print(np.shape(train))\n",
    "print(train[0,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 4, 7, ..., 4, 5, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tl = pd.read_csv('train_labels.csv', delimiter = ',') #read dataset\n",
    "tl.head(5)\n",
    "tl_n = tl.to_numpy()\n",
    "trn_y = tl_n[:,1]\n",
    "trn_y[trn_y=='FM']=0\n",
    "trn_y[trn_y=='OQPSK']=1\n",
    "trn_y[trn_y=='BPSK']=2\n",
    "trn_y[trn_y=='8PSK']=3\n",
    "trn_y[trn_y=='AM-SSB-SC']=4\n",
    "trn_y[trn_y=='4ASK']=5\n",
    "trn_y[trn_y=='16PSK']=6\n",
    "trn_y[trn_y=='AM-DSB-SC']=7\n",
    "trn_y[trn_y=='QPSK']=8\n",
    "trn_y[trn_y=='OOK']=9\n",
    "\n",
    "trn_y=trn_y.astype('int')\n",
    "print(np.shape(trn_y))\n",
    "print(type(trn_y))\n",
    "trn_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import moment\n",
    "\n",
    "def feature_extraction(given_data):\n",
    "    \n",
    "    train_data_cmplx = given_data[:,:,0] + 1j*given_data[:,:,1]\n",
    "    data = np.fft.fft(train_data_cmplx,axis=1)\n",
    "    \n",
    "    dim = len(data)\n",
    "    \n",
    "    M20 = moment(data,2,axis=1)\n",
    "    print(np.shape(M20))\n",
    "\n",
    "    M21 = data * np.conj(data)\n",
    "    M21 = moment(M21, 1, axis=1)\n",
    "    print(np.shape(M21))\n",
    "\n",
    "    M22 = np.power(data,0) * np.power(np.conj(data),2)\n",
    "    M22 = moment(M22, 1, axis=1)\n",
    "    print(np.shape(M22))\n",
    "\n",
    "    M40 = np.power(data,4) * np.power(np.conj(data),0)\n",
    "    M40 = moment(M40, 1, axis=1)\n",
    "    print(np.shape(M40))\n",
    "\n",
    "    M41 = np.power(data,4) * np.power(np.conj(data),0)\n",
    "    M41 = moment(M41, 1, axis=1)\n",
    "    print(np.shape(M41))\n",
    "\n",
    "    M42 = np.power(data,4) * np.power(np.conj(data),0)\n",
    "    M42 = moment(M42, 1, axis=1)\n",
    "    print(np.shape(M42))\n",
    "\n",
    "    M43 = np.power(data,4) * np.power(np.conj(data),0)\n",
    "    M43 = moment(M43, 1, axis=1)\n",
    "    print(np.shape(M43))\n",
    "\n",
    "    M60 = np.power(data,6) * np.power(np.conj(data),0)\n",
    "    M60 = moment(M60, 1, axis=1)\n",
    "    print(np.shape(M60))\n",
    "\n",
    "    M61 = np.power(data,5) * np.power(np.conj(data),1)\n",
    "    M61 = moment(M61, 1, axis=1)\n",
    "    print(np.shape(M61))\n",
    "\n",
    "    M62 = np.power(data,4) * np.power(np.conj(data),2)\n",
    "    M62 = moment(M62, 1, axis=1)\n",
    "    print(np.shape(M62))\n",
    "\n",
    "    M63 = np.power(data,3) * np.power(np.conj(data),3)\n",
    "    M63 = moment(M63, 1, axis=1)\n",
    "    print(np.shape(M63))\n",
    "\n",
    "\n",
    "    C40 = M40 - 3*np.power(M20,2)\n",
    "    print(np.shape(C40))\n",
    "\n",
    "    C41 = M40 - 3*M20 * M21\n",
    "    print(np.shape(C41))\n",
    "\n",
    "    C42 = M42 - np.power(np.absolute(M20),2) - 2*np.power(M21,2)\n",
    "    print(np.shape(C42))\n",
    "\n",
    "    C60 = M60 - 16*M20*M40 + 30*np.power(np.absolute(M20),2)\n",
    "    print(np.shape(C60))\n",
    "\n",
    "    C61 = M61 - 5*M21*M40 - 10*M20*M41 + 30*np.power(np.absolute(M20),2)*M21\n",
    "    print(np.shape(C61))\n",
    "\n",
    "    C62 = M62 - 6*M20*M42 - 8*M21*M41 -M22*M40 + 6*np.power(np.absolute(M20),2)*M22 + 24*np.power(np.absolute(M21),2)*M20 \n",
    "    print(np.shape(C62))\n",
    "\n",
    "    C63 = M63 - 9*M21*M42 + 12*np.power(M21,3) - 3*M20*M43 - 3*M22*M41 + 18*M20*M21*M22\n",
    "    print(np.shape(C63))\n",
    "    \n",
    "    output = [M20, M21, M22, M40, M41, M42, M43, M60, M61, M62, M63, C40, C41, C42, C60, C61, C62, C63]\n",
    "    output = np.reshape(output,(dim,18))\n",
    "    \n",
    "    output_real = np.real(output)\n",
    "    output_imag = np.imag(output)\n",
    "    \n",
    "    output = [output_real,output_imag]\n",
    "    output = np.reshape(output,(dim,36))\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=feature_extraction(train_data)\n",
    "print(np.shape(train_features))\n",
    "print(type(train_features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=10,kernel='rbf',gamma='auto')\n",
    "clf.fit(train_features,trn_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "train_x = np.reshape(train_data,(30000,2048))\n",
    "clf = SVC(C=10,kernel='poly',degree=2,gamma='auto')\n",
    "clf.fit(train_x[0:10000,:],trn_y[0:10000])\n",
    "y_new_trn=clf.predict(train_x[0:10000,:])\n",
    "accuracy_trn=accuracy_score(y_new_trn, trn_y[0:10000])\n",
    "print(accuracy_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tst = []\n",
    "accuracy_trn = []\n",
    "n = np.array(range(20))\n",
    "C = 2**n\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(20):\n",
    "    clf = SVC(C=C[i],kernel='poly',degree=4,gamma='auto')\n",
    "    clf.fit(train_features[0:30000,:],trn_y[0:30000])\n",
    "    y_new_trn=clf.predict(train_features[0:30000,:])\n",
    "    accuracy_trn=np.append(accuracy_trn,accuracy_score(y_new_trn, trn_y[0:30000]))\n",
    "\n",
    "max_acc = np.amax(accuracy_trn)\n",
    "#plt.semilogx(C, accuracy_tst)\n",
    "plt.semilogx(C, accuracy_trn)\n",
    "plt.title(\"SVM with Gaussian kernel\")\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "print('The maximum testing accuracy achieved with SVM with Gaussian kernel is: ' + str(max_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=0,max_depth=100,learning_rate=0.2)\n",
    "clf.fit(train_features[0:10000], trn_y[0:10000])\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_new_trn=clf.predict(train_features[0:10000,:])\n",
    "accuracy_trn=accuracy_score(y_new_trn,trn_y[0:10000])\n",
    "print(accuracy_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(given_data):\n",
    "    dim=len(given_data)\n",
    "    data_comp=given_data[:,:,0] + 1j*given_data[:,:,1]\n",
    "    data = np.zeros((dim,1024,2))\n",
    "    data[:,:,0] = np.absolute(data_comp)\n",
    "    data[:,:,1] = np.angle(data_comp)\n",
    "    print(np.shape(data))\n",
    "    print(data[0])\n",
    "    data=given_data\n",
    "    for i in range(dim):\n",
    "        for j in range(2):\n",
    "            mu = np.mean(data[i,:,j])\n",
    "            data[i,:,j] = data[i,:,j]-np.mean(data[i,:,j])\n",
    "            std=np.var(data[i,:,j])\n",
    "            data[i,:,:] = data[i,:,:]/std\n",
    "    return data\n",
    "trn_norm = normalise(x_trn)\n",
    "print(np.shape(trn_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "batch_size = 300\n",
    "num_classes = 24\n",
    "epochs = 500\n",
    "input_shape = (1024,2)\n",
    "fil = 64\n",
    "ker=2\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(trn_y, num_classes)\n",
    "\n",
    "#Input,output and hidden layers\n",
    "model = Sequential()\n",
    "model.add(Conv1D(fil, kernel_size= ker,\n",
    "                 activation='relu', padding=\"same\",\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "#Reduces the input data to half\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(fil, ker,padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(fil, ker,padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(fil, ker,padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(fil, ker,padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(fil, ker,padding=\"same\",activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(fil, ker,padding=\"same\", ,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(128, activation='selu'))\n",
    "model.add(Dense(128, activation='selu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adam(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "#Model train in batches\n",
    "model.summary()\n",
    "model.fit(trn_norm, y_train, batch_size = batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_norm = normalise(x_test)\n",
    "y_pred = model.predict(tst_norm)\n",
    "\n",
    "\n",
    "\n",
    "print(np.shape(y_pred))\n",
    "\n",
    "label = np.zeros(20000)\n",
    "for i in range (0,19999):\n",
    "    m = np.argmax(y_pred[i][:])\n",
    "    label[i] = m.astype(int)\n",
    "test_y=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features=feature_extraction(test_data)\n",
    "tst_y=clf.predict(test_features)\n",
    "\n",
    "print(np.shape(tst_y))\n",
    "\n",
    "test_y=np.empty(np.shape(tst_y), dtype=object)\n",
    "for i in range(19999):\n",
    "  #print(i)\n",
    "    if(tst_y[i]==0):\n",
    "            test_y[i]='FM'\n",
    "    if(tst_y[i]==1):\n",
    "        test_y[i]='QPSK'\n",
    "    if(tst_y[i]==2):\n",
    "        test_y[i]='BPSK'\n",
    "    if(tst_y[i]==3):\n",
    "        test_y[i]='8PSK'\n",
    "    if(tst_y[i]==4):\n",
    "        test_y[i]='AM-SSB-SC'\n",
    "    if(tst_y[i]==5):\n",
    "        test_y[i]='4ASK'\n",
    "    if(tst_y[i]==6):\n",
    "        test_y[i]='16PSK'\n",
    "    if(tst_y[i]==7):\n",
    "        test_y[i]='AM-DSB-SC'\n",
    "    if(tst_y[i]==8):\n",
    "        test_y[i]='QPSK'\n",
    "    if(tst_y[i]==9):\n",
    "        test_y[i]='OOK'\n",
    "\n",
    "print(np.shape(test_y))\n",
    "ID = np.linspace(0,19999,num=20000)\n",
    "test_label = test_y\n",
    "print(np.shape(test_label))\n",
    "test_label=np.reshape(test_label,(20000))\n",
    "test_csv = pd.DataFrame(data=test_label,columns=[\"Category\"])\n",
    "test_csv.to_csv('test_svm.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
